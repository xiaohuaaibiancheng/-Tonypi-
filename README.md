

# Tonypi 多模态机器人项目

本项目旨在赋予 Tonypi 机器人更强大的多模态交互能力，特别是在复杂指令理解、场景认知与行为模仿方面。通过丰富的模块设计，实现了从低层动作到高层智能的全面控制。

## 目录结构

```
├── ActionGroups/     # 预设动作文件，控制机器人执行具体动作
├── Functions/        # 机器人核心功能实现
├── models/ 存放视觉识别相关模型文件       
├── command.py        # 多模态扩展功能的主入口
├── Transport_to_words.py #利用语音转文字api 转文字的脚本
├── tts_ws_python3_demo.py # 文本转音频的脚本
```

## 主要功能介绍

### 1. ActionGroups 动作组

- 存放机器人的动作文件，每个文件对应一组动作序列。
- 执行相应动作组文件后，机器人将完成特定动作（如挥手、踢球、搬运物体等）。

### 2. Functions 文件夹

包含各种控制机器人行为的脚本和模块，包括：

1. **视觉颜色识别**：通过摄像头识别不同颜色目标。
2. **简单动作控制**：如前进、后退、转向等基础动作操作。
3. **指定位置物体搬运**：机器人可自主寻路至目标点并搬运物体。
4. **定线巡航**：沿预设路线自动巡航。
5. **人脸追踪**：自动识别人脸并持续跟随。
6. **物体跟踪**：对指定物体进行跟踪。
7. **跟踪踢球**：识别并追踪球体，完成踢球动作。

### 3. command.py 多模态扩展

实现了更高层次的多模态智能能力，包括：

1. **场景描述**：分析当前环境，生成自然语言的场景描述。
2. **复制指令执行**：通过模仿演示动作，实现指令复制与动作复现。
3. **智能对话（带长记忆）**：支持与用户进行上下文相关的多轮对话，并具备长时记忆能力。
4. **行为模仿**：学习和复现给定的动作序列，实现人类动作模仿。

## 快速开始

1. 克隆仓库：
   ```bash
   git clone https://github.com/xiaohuaaibiancheng/-Tonypi-.git
   ```
2. 按照 `Functions/` 目录下的说明，部署相应依赖和环境。
3. 运行 `command.py`，体验多模态交互与智能行为功能。

## 贡献与交流

欢迎对本项目提出建议和贡献代码。  
如有问题请通过 Issues 或 Discussions 进行反馈。

